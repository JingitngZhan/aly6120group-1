Modeling Phase – Predictive Analytics Approach for NY Bank Loan Approval Optimization

The goal of the modeling phase in the CRISP-DM cycle is to transition from hindsight understanding historical approval delays to foresight that helps NY Bank predict which loan applications are likely to encounter bottlenecks. Based on the structure of the Kaggle MIT loan dataset and the business need to classify applications by risk of delay, this project will employ two predictive modeling approaches: Logistic Regression and Random Forest Classification. Using both models enables comparison between interpretability and predictive power, ensuring that NY Bank’s senior leadership receives a decision environment that is both transparent and actionable.

Model Selection and Rationale
Logistic Regression is selected as the baseline model because it is interpretable, easy to deploy, and widely used in financial decision systems. It predicts the probability that an application will experience delays based on customer demographics, credit metrics, and documentation patterns. Its coefficients help NY Bank identify which factors such as missing documents, low credit scores, or high debt-to-income ratios are most strongly associated with slow approvals. This aligns with the bank’s need for clear justification in regulated environments.
Random Forest Classification, on the other hand, provides higher predictive accuracy and handles nonlinear relationships that the logistic model cannot capture. It also excels at identifying complex interactions between variables such as employment length, income stability, loan purpose, and documentation completeness. Random Forests are resilient to noisy data and outliers, making them suitable for the bank’s operational data, which may include human entry errors, inconsistent credit records, and missing values.

Predictive Analytics Approach for NY Bank Loan Approval Optimization 
The modeling phase of the CRISP-DM process shifts NY Bank from hindsight about past loan approval delays to foresight that identifies which new applications are at risk of bottlenecks. Based on the MIT Kaggle loan dataset and the bank’s operational needs, two models are selected: Logistic Regression and Random Forest Classification. Using both aligns with Agile Analytics principles by balancing interpretability and predictive performance (Collier, 2012).
Logistic Regression is used as the baseline model because it is interpretable, transparent and easy to deploy important characteristics in regulated financial systems. It provides probability estimates that help identify which features such as documentation completeness or creditworthiness, contribute most to delays. This supports clear justification for decisions which is essential for compliance (Provost & Fawcett, 2013). However, Logistic Regression struggles with nonlinear relationships and is sensitive to outliers and missing values which are common in operational banking data (Saporito, 2015).
Random Forest Classification complements the baseline model by offering superior predictive accuracy and resilience to noisy or incomplete data. It captures complex interactions such as those between employment stability and loan purpose that Logistic Regression cannot model. It is especially useful when dealing with inconsistent credit records or human entry errors. The primary limitations of Random Forests are their reduced interpretability and greater computational cost.
To execute this modeling phase effectively, collaboration across several roles is required. I worked closely with a Data Engineer to ensure data quality, a Business Analyst to validate assumptions and a Compliance Officer to ensure regulatory alignment. A Machine Learning Engineer supported model deployment, while a Product Manager ensured the models align with NY Bank’s strategic goals. This cross-functional approach ensured both accuracy and operational relevance.

Data Quality Issues
While exploring the dataset and preparing it for modeling, I noticed several data quality issues that could influence the performance and reliability of the predictive models. First, some of the numeric variables—especially the asset-related fields—contained negative values. Since asset values cannot logically be negative, these entries likely resulted from data entry mistakes or system inconsistencies. I handled this issue by clipping negative values to zero and trimming extreme outliers using percentile-based winsorization, which helped stabilize the distributions and prevent them from disproportionately affecting the models.
Second, even though the dataset did not contain large amounts of missing data, some variables still required imputation. To make the data usable across different models, I applied median imputation for numeric fields and most-frequent imputation for categorical fields through a preprocessing pipeline. Without this step, the models would have either dropped rows or misinterpreted missing patterns, which could reduce overall model performance.
Third, the loan_status variable demonstrated a moderate class imbalance, with more approved cases than rejected ones. This imbalance can cause the model to favor the majority class and inflate accuracy without truly improving predictive power. To address this, I used stratified sampling during train–test split and enabled class weighting in the classifiers so the model treats both classes more evenly.
Lastly, the EDA plots highlighted strong skewness in income, loan amounts, and various asset values, which suggests the presence of extreme outliers and substantial variation across customer groups. These distributional shifts indicate that the relationship between predictors and the target variable could change depending on applicant segments, making careful preprocessing and validation essential.


Patterns the Model Should Illustrate
Based on the exploratory data analysis and the outputs from the models, there are several important patterns that the predictive models are expected to capture and illustrate. One of the clearest patterns involves income: applicants with higher annual incomes tend to have much higher approval rates. The boxplots and histograms show a noticeable difference between approved and rejected applicants, suggesting that income acts as a significant threshold variable for loan eligibility.
A similar but even stronger pattern appears in the CIBIL score. Approved applicants consistently show higher CIBIL scores with very little overlap with rejected applicants. Both the Random Forest and Gradient Boosting models rank CIBIL score as the most important feature, reinforcing its central role in credit decision-making. This suggests the model should use CIBIL score as a primary indicator of creditworthiness.
The visualizations comparing education levels and employment status also reveal meaningful trends. Applicants with higher education tend to have higher approval rates, while self-employed applicants appear to face more rejections compared to salaried applicants. These patterns align with common lending behavior and indicate that demographic variables interact with financial features to affect risk assessment.
Asset values—such as residential, commercial, and bank assets—also show strong positive associations with approval outcomes. Even after adjusting for outliers, applicants with higher asset levels are more likely to get approved, which is consistent with how lenders evaluate collateral strength.
Finally, the feature importance rankings and ROC curves suggest that the models are not only capturing individual predictors but also their interactions—such as applicants with high loan amounts but low CIBIL scores, or low incomes paired with short loan terms. These interaction patterns help highlight riskier subgroups and can guide more precise decision-making.




